# -*- coding: utf-8 -*-
"""text_classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17OZIJWKHBE4gc0czNRR3KCiRqWKfmHDO
"""

import numpy as np
import math
import pandas as pd
import re
import ssl
import nltk
import pickle
from sklearn.model_selection import train_test_split
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer 
import warnings
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import confusion_matrix
import csv
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
warnings.filterwarnings("ignore")

ps = PorterStemmer()
lemma = WordNetLemmatizer()

# TASK CELL

def clean_review(review):
    '''
    Input:
        review: a string containing a review.
    Output:
        review_cleaned: a processed review. 

    '''
    words= review.lower()
    words= re.sub(r'https?://\S+','',words)
    words= re.sub(r'[^\w\s]','',words)
    words= word_tokenize(words)
    reviews=[word for word in words if word not in stopwords.words('english')]
    # review_cleaned = [ps.stem(word) for word in reviews]
    review_cleaned = [lemma.lemmatize(word) for word in reviews]
    return review_cleaned

# TASK 4 CELL

def naive_bayes_predict(review, logprior, loglikelihood):
    '''
    Params:
        review: a string
        logprior: a number
        loglikelihood: a dictionary of words mapping to numbers
    Return:
        total_prob: the sum of all the loglikelihoods of each word in the review (if found in the dictionary) + logprior (a number)

    '''
    
    # process the review to get a list of words
    word_l = clean_review(review)

    # initialize probability to zero
    total_prob = 0

    # add the logprior
    total_prob += logprior

    for word in word_l:

        # check if the word exists in the loglikelihood dictionary
        if word in loglikelihood.keys():
            # add the log likelihood of that word to the probability
            total_prob += loglikelihood[word]
    
    if total_prob > 0:
        total_prob = 1
    else:
        total_prob = 0

    return total_prob

logprior,loglikelihood = pickle. load(open("output.pkl","rb"))
while True:
    input_review = input("Enter your review: ")
    if input_review=='X' or input_review=='x':
        print("Classification ended")
        break
    clean_review(input_review)
    x = naive_bayes_predict(input_review, logprior, loglikelihood)
    if(x==0):
        print("It's a positive review")
    if(x==1):
        print("It's a negative review")